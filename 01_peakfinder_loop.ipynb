{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRNsuite Demo Workflows\n",
    "\n",
    "This notebook demonstrates the interactive vs non-interactive workflows for processing electrophysiology data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Workflow Looping Through Files\n",
    "\n",
    "This workflow allows you to loop through all files in the data directory and process them interactively.\n",
    "\n",
    "Data is saved in the results directory with the same filename as the original data, alongside the metadata for that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Spike Detection (loops through all files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files to process:\n",
      "  - 20231103-M05-sucr-100-Gal-A2-01.txt\n",
      "  - 20231106-M01-sucr-100-Gal-A1-02.txt\n",
      "  - 20231103-M04-sucr-100-Gal-A2-02.txt\n",
      "  - 20231106-F02-sucr-100-Gal-A2-02.txt\n",
      "  - 20231103-M05-sucr-100-Gal-A1-02.txt\n",
      "  - 20231103-M05-sucr-100-Gal-A3-02.txt\n",
      "  - 20231106-M01-sucr-100-Gal-A2-02.txt\n",
      "  - 20231103-M04-sucr-100-Gal-A1-02.txt\n",
      "  - 20231106-F02-sucr-100-Gal-A3-02.txt\n",
      "\n",
      "Processing 20231103-M05-sucr-100-Gal-A2-01.txt...\n",
      "\n",
      "=== Interactive Pre-processing ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 19:13:33.411 Python[24452:15803657] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-13 19:13:33.411 Python[24452:15803657] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected segment from index 419319 to 509319\n",
      "Zoomed data figure saved to: results/20231103-M05-sucr-100-Gal-A2-01/zoomed_data.png\n",
      "Successfully saved processed data to: results/20231103-M05-sucr-100-Gal-A2-01/interactive_processed.csv\n",
      "\n",
      "=== Interactive Spike Detection ===\n",
      "Initial threshold calculated: 2.3982556828280686\n",
      "Data range: min=-9.20173212259001, max=10.85913567763796\n",
      "Selected threshold: 2.3982556828280686\n",
      "Final threshold value: 2.3982556828280686\n",
      "Using thresholds: upper=2.3983, lower=1.9186\n",
      "\n",
      "=== Extracting Spike Waveforms ===\n",
      "Waveform figure saved to: results/20231103-M05-sucr-100-Gal-A2-01/waveforms_plot.png\n",
      "\n",
      "=== Automated Workflow ===\n",
      "Auto-selected signal from index 419319 to 509319 (duration: 3.0s)\n",
      "Successfully saved processed data to: results/20231103-M05-sucr-100-Gal-A2-01/auto_processed.csv\n",
      "Saved metadata to: results/20231103-M05-sucr-100-Gal-A2-01/metadata.json\n",
      "\n",
      "=== Compare Results ===\n",
      "Interactive workflow detected 202 spikes\n",
      "Automated workflow detected 202 spikes\n",
      "Extracted 202 waveforms\n",
      "Comparison figure saved to: results/20231103-M05-sucr-100-Gal-A2-01/spike_comparison.png\n",
      "\n",
      "Moving to next file...\n",
      "\n",
      "Processing 20231106-M01-sucr-100-Gal-A1-02.txt...\n",
      "\n",
      "=== Interactive Pre-processing ===\n",
      "Selected segment from index 605927 to 695927\n",
      "Zoomed data figure saved to: results/20231106-M01-sucr-100-Gal-A1-02/zoomed_data.png\n",
      "Successfully saved processed data to: results/20231106-M01-sucr-100-Gal-A1-02/interactive_processed.csv\n",
      "\n",
      "=== Interactive Spike Detection ===\n",
      "Initial threshold calculated: 2.4394394492258655\n",
      "Data range: min=-8.821693145056098, max=13.882781429587563\n",
      "Selected threshold: 2.4394394492258655\n",
      "Final threshold value: 2.4394394492258655\n",
      "Using thresholds: upper=2.4394, lower=1.9516\n",
      "\n",
      "=== Extracting Spike Waveforms ===\n",
      "Waveform figure saved to: results/20231106-M01-sucr-100-Gal-A1-02/waveforms_plot.png\n",
      "\n",
      "=== Automated Workflow ===\n",
      "Auto-selected signal from index 605927 to 695927 (duration: 3.0s)\n",
      "Successfully saved processed data to: results/20231106-M01-sucr-100-Gal-A1-02/auto_processed.csv\n",
      "Saved metadata to: results/20231106-M01-sucr-100-Gal-A1-02/metadata.json\n",
      "\n",
      "=== Compare Results ===\n",
      "Interactive workflow detected 199 spikes\n",
      "Automated workflow detected 199 spikes\n",
      "Extracted 199 waveforms\n",
      "Comparison figure saved to: results/20231106-M01-sucr-100-Gal-A1-02/spike_comparison.png\n",
      "\n",
      "Stopping processing. Files completed:\n",
      "  - 20231103-M05-sucr-100-Gal-A2-01.txt\n",
      "  - 20231106-M01-sucr-100-Gal-A1-02.txt\n",
      "\n",
      "Files remaining:\n",
      "  - 20231103-M04-sucr-100-Gal-A2-02.txt\n",
      "  - 20231106-F02-sucr-100-Gal-A2-02.txt\n",
      "  - 20231103-M05-sucr-100-Gal-A1-02.txt\n",
      "  - 20231103-M05-sucr-100-Gal-A3-02.txt\n",
      "  - 20231106-M01-sucr-100-Gal-A2-02.txt\n",
      "  - 20231103-M04-sucr-100-Gal-A1-02.txt\n",
      "  - 20231106-F02-sucr-100-Gal-A3-02.txt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import grnsuite.preprocessing as preprocessing\n",
    "import grnsuite.spike_detection as spikes\n",
    "import grnsuite.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib.widgets import Button\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")  # Ensures the correct interactive backend is used\n",
    "\n",
    "# Load parameters\n",
    "params = utils.load_parameters('parameters.yaml')\n",
    "\n",
    "# Get list of files to process\n",
    "if params['process_mode'] == 'all':\n",
    "    # Get all .txt files in the data directory\n",
    "    files = glob.glob(os.path.join(\"data\", \"*.txt\"))\n",
    "    filenames = [os.path.basename(f) for f in files]\n",
    "else:\n",
    "    # Get specific files from parameters if they exist\n",
    "    filenames = []\n",
    "    if 'recordings' in params:\n",
    "        filenames = [f\"{name}.txt\" for name in params['recordings'].keys()]\n",
    "    else:\n",
    "        raise ValueError(\"No recordings specified in parameters.yaml and process_mode is not 'all'\")\n",
    "\n",
    "print(f\"Found {len(filenames)} files to process:\")\n",
    "for f in filenames:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Add global control variable\n",
    "should_end = False\n",
    "\n",
    "# Process each file\n",
    "for filename in filenames:\n",
    "    print(f\"\\nProcessing {filename}...\")\n",
    "    \n",
    "    # Set up paths\n",
    "    filepath = os.path.join(\"data\", filename)\n",
    "    sample_name = filename.replace('.txt', '')\n",
    "    output_dir = os.path.join(\"results\", sample_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get metadata from filename\n",
    "    metadata = utils.parse_filename_metadata(sample_name, params)\n",
    "    \n",
    "    print(\"\\n=== Interactive Pre-processing ===\")\n",
    "    # Load raw data\n",
    "    raw_data = preprocessing._load_ephys_data(filepath)\n",
    "    \n",
    "    # Step-by-step processing (interactive path)\n",
    "    selected_signal = preprocessing.interactive_contact_selection(raw_data)\n",
    "    filtered_signal = preprocessing.filter_signal(selected_signal, params)\n",
    "    \n",
    "    # Save zoomed data visualization\n",
    "    zoomed_signal, current_time = preprocessing.zoom_to_region(filtered_signal, params, output_dir=output_dir)\n",
    "    \n",
    "    mad_signal = preprocessing.normalize_signal(zoomed_signal)\n",
    "    \n",
    "    # Save the interactive results\n",
    "    temp_data_path = os.path.join(output_dir, 'interactive_processed.csv')\n",
    "    preprocessing.save_results(mad_signal, current_time, temp_data_path)\n",
    "    \n",
    "    print(\"\\n=== Interactive Spike Detection ===\")\n",
    "    # Run automatic detection\n",
    "    spikes_file_auto, spike_times_auto, spike_values_auto = spikes.schmidt_trigger_auto(\n",
    "        temp_data_path, \n",
    "        output_dir\n",
    "    )\n",
    "\n",
    "    # Allow manual threshold adjustment and detect spikes\n",
    "    manual_threshold = spikes.adjust_threshold(mad_signal)\n",
    "    spikes_file_manual, spike_times, spike_values = spikes.detect_spikes_manual_threshold(\n",
    "        temp_data_path,\n",
    "        output_dir,\n",
    "        threshold=manual_threshold\n",
    "    )\n",
    "    \n",
    "    # Extract and save waveforms using the manual threshold detection results\n",
    "    print(\"\\n=== Extracting Spike Waveforms ===\")\n",
    "    waveforms_file = spikes.extract_waveforms(\n",
    "        data_file=temp_data_path,\n",
    "        spikes_file=spikes_file_manual,  # Use the manual threshold results\n",
    "        output_dir=output_dir,\n",
    "        pre_peak_length=2,  # 2ms before spike\n",
    "        post_peak_length=2   # 2ms after spike\n",
    "    )\n",
    "    \n",
    "    # Load the waveforms for visualization\n",
    "    waveforms_df = pd.read_csv(waveforms_file)\n",
    "    waveforms = waveforms_df.values\n",
    "    \n",
    "    # Plot and save waveforms visualization\n",
    "    avg_waveform, std_waveform = spikes.plot_waveforms(\n",
    "        waveforms=waveforms,\n",
    "        pre_peak_ms=2.0,\n",
    "        post_peak_ms=2.0,\n",
    "        show_time_axis=True,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Automated Workflow ===\")\n",
    "    # Process data using the complete automated workflow\n",
    "    auto_output_path = os.path.join(output_dir, 'auto_processed.csv')\n",
    "    preprocessing.process_recording(\n",
    "        input_file=filepath,\n",
    "        output_file=auto_output_path,\n",
    "        interactive=False  # Use automated contact selection\n",
    "    )\n",
    "\n",
    "    # Load and plot results\n",
    "    processed_data = pd.read_csv(auto_output_path)\n",
    "    detected_spikes = pd.read_csv(spikes_file_auto)  # Using the auto detection results\n",
    "\n",
    "    print(\"\\n=== Compare Results ===\")\n",
    "    print(f\"Interactive workflow detected {len(spike_times)} spikes\")\n",
    "    print(f\"Automated workflow detected {len(detected_spikes)} spikes\")\n",
    "    print(f\"Extracted {waveforms.shape[0]} waveforms\")\n",
    "\n",
    "    # Plot both results overlaid\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.plot(current_time, mad_signal, 'b-', alpha=0.5, label=\"Signal\")\n",
    "\n",
    "    # Add offset to interactive points for better visualization\n",
    "    y_offset = 0.5  # Adjust this value to change the separation\n",
    "    plt.scatter(spike_times, spike_values + y_offset, \n",
    "               color='red', label=\"Interactive\", alpha=0.6)\n",
    "    plt.scatter(detected_spikes['spike_times'], detected_spikes['spike_values'], \n",
    "               color='green', label=\"Automated\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Spike Detection Results - {sample_name}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Normalized Voltage\")\n",
    "    \n",
    "    # Save comparison figure\n",
    "    comparison_path = os.path.join(output_dir, 'spike_comparison.png')\n",
    "    plt.savefig(comparison_path, dpi=300)\n",
    "    print(f\"Comparison figure saved to: {comparison_path}\")\n",
    "\n",
    "    # Add Next and End buttons\n",
    "    if filename != filenames[-1]:\n",
    "        next_button = Button(plt.axes([0.7, 0.01, 0.1, 0.05]), 'Next File')\n",
    "        \n",
    "        def handle_next(event):\n",
    "            plt.close(fig)\n",
    "            print(f\"\\nMoving to next file...\")\n",
    "\n",
    "        next_button.on_clicked(handle_next)\n",
    "\n",
    "    # Always show End button\n",
    "    end_button = Button(plt.axes([0.85, 0.01, 0.1, 0.05]), 'End')\n",
    "    \n",
    "    def handle_end(event):\n",
    "        plt.close(fig)\n",
    "        print(\"\\nStopping processing. Files completed:\")\n",
    "        for f in filenames[:filenames.index(filename) + 1]:\n",
    "            print(f\"  - {f}\")\n",
    "        if filename != filenames[-1]:\n",
    "            print(\"\\nFiles remaining:\")\n",
    "            for f in filenames[filenames.index(filename) + 1:]:\n",
    "                print(f\"  - {f}\")\n",
    "        global should_end  # Use global variable to control the loop\n",
    "        should_end = True\n",
    "\n",
    "    end_button.on_clicked(handle_end)\n",
    "    plt.show()\n",
    "\n",
    "    # Check if we should end processing\n",
    "    if should_end:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
