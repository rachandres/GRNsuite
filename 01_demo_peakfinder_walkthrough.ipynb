{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Preprocessing Visualization Notebook\n",
    "\n",
    "This notebook provides an interactive visualization of the pre-processing steps for a single recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries. If any of these libraries are not installed, you can install them using pip install grnsuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grnsuite.preprocessing as preprocessing\n",
    "import grnsuite.spike_detection as spikes\n",
    "import grnsuite.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib.widgets import Button, RadioButtons\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")  # Ensures the correct interactive backend is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the parameters from the parameters.yaml file and load the file paths to your data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 files to process:\n",
      "  0. 20231103-M05-sucr-100-Gal-A2-01.txt\n",
      "  1. 20231106-M01-sucr-100-Gal-A1-02.txt\n",
      "  2. 20231103-M04-sucr-100-Gal-A2-02.txt\n",
      "  3. 20231106-F02-sucr-100-Gal-A2-02.txt\n",
      "  4. 20231103-M05-sucr-100-Gal-A1-02.txt\n",
      "  5. 20231103-M05-sucr-100-Gal-A3-02.txt\n",
      "  6. 20231106-M01-sucr-100-Gal-A2-02.txt\n",
      "  7. 20231103-M04-sucr-100-Gal-A1-02.txt\n",
      "  8. 20231106-F02-sucr-100-Gal-A3-02.txt\n"
     ]
    }
   ],
   "source": [
    "# Load parameters\n",
    "params = utils.load_parameters('parameters.yaml')\n",
    "\n",
    "# Get list of files to process\n",
    "if params['process_mode'] == 'all': \n",
    "    # Get all .txt files in the data directory\n",
    "    files = glob.glob(os.path.join(\"data\", \"*.txt\"))\n",
    "    filenames = [os.path.basename(f) for f in files]\n",
    "else:\n",
    "    # Get specific files from parameters if they exist\n",
    "    filenames = []\n",
    "    if 'recordings' in params:\n",
    "        filenames = [f\"{name}.txt\" for name in params['recordings'].keys()]\n",
    "    else:\n",
    "        raise ValueError(\"No recordings specified in parameters.yaml and process_mode is not 'all'\")\n",
    "\n",
    "print(f\"Found {len(filenames)} files to process:\")\n",
    "for i, f in enumerate(filenames):\n",
    "    print(f\"  {i-1+1}. {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a file to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 20231103-M05-sucr-100-Gal-A1-02.txt...\n"
     ]
    }
   ],
   "source": [
    "# Let user select a file to process - should be a number between 0 and the number of files.\n",
    "file_index = int(input(f\"Select a file to process (1-{len(filenames)}): \")) - 1\n",
    "filename = filenames[file_index]\n",
    "print(f\"\\nProcessing {filename}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up paths to the input and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "sample_name = filename.replace('.txt', '')\n",
    "output_dir = os.path.join(\"results\", sample_name)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metadata from the file name - note, this relies on the parameters.yaml file that will dicate the order of the metadata in the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'date': '20231106', 'animal_id': 'F02', 'stimulus': 'sucr', 'concentration': '100', 'location': 'Gal', 'sensillum_id': 'A2', 'replicate': '02'}\n"
     ]
    }
   ],
   "source": [
    "# Get metadata from filename\n",
    "metadata = utils.parse_filename_metadata(sample_name, params)\n",
    "print(f\"Metadata: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the metadata is correct. If it isn't, you can edit the parameters.yaml file to change the order of the metadata in the file name.\n",
    "\n",
    "\n",
    "## Step 1: Load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 1: Loading Raw Data ===\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: Load Raw Data ===\n",
    "print(\"\\n=== STEP 1: Loading Raw Data ===\")\n",
    "raw_data = preprocessing._load_ephys_data(filepath)\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# Visualize raw data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(raw_data, 'k-', alpha=0.7)\n",
    "plt.title(\"Step 1: Raw Electrophysiology Data\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Select the contact artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 2: Contact Artifact Selection ===\n",
      "Use the slider to adjust the starting point of the recording.\n",
      "The contact artifact should be at the beginning of the red section.\n",
      "Selected segment from index 69970 to 159970\n"
     ]
    }
   ],
   "source": [
    "# === STEP 2: Contact Artifact Selection ===\n",
    "print(\"\\n=== STEP 2: Contact Artifact Selection ===\")\n",
    "print(\"Use the slider to adjust the starting point of the recording.\")\n",
    "print(\"The contact artifact should be at the beginning of the red section.\")\n",
    "\n",
    "matplotlib.use(\"TkAgg\")  # Use TkAgg for interactive selection\n",
    "# The function now handles backend switching internally\n",
    "selected_signal = preprocessing.interactive_contact_selection(raw_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected signal length: 90000 samples\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(selected_signal, 'r-')\n",
    "plt.title(\"Step 2: Selected Signal After Contact Artifact Selection\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Selected signal length: {len(selected_signal)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Filter the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 3: Filtering the Signal ===\n",
      "Applying bandpass filter (100-1000 Hz) and noise removal\n",
      "Filtered signal properties:\n",
      "  - Mean: -0.0914\n",
      "  - Std Dev: 49.6228\n"
     ]
    }
   ],
   "source": [
    "# === STEP 3: Filtering ===\n",
    "print(\"\\n=== STEP 3: Filtering the Signal ===\")\n",
    "print(f\"Applying bandpass filter ({params['filter_low']}-{params['filter_high']} Hz) and noise removal\")\n",
    "\n",
    "filtered_signal = preprocessing.filter_signal(selected_signal, params)\n",
    "\n",
    "# Visualize filtering effects\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Original signal\n",
    "axes[0].plot(selected_signal, 'k-', alpha=0.7)\n",
    "axes[0].set_title(\"Before Filtering (Raw Selected Signal)\")\n",
    "axes[0].set_ylabel(\"Voltage\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# After bandpass filter\n",
    "bandpass_only = preprocessing._apply_filter(\n",
    "    selected_signal, \n",
    "    [params['filter_low'], params['filter_high']], \n",
    "    'bandpass', \n",
    "    fs=params['sampling_rate']\n",
    ")\n",
    "axes[1].plot(bandpass_only, 'b-', alpha=0.7)\n",
    "axes[1].set_title(f\"After Bandpass Filter ({params['filter_low']}-{params['filter_high']} Hz)\")\n",
    "axes[1].set_ylabel(\"Voltage\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# After noise removal\n",
    "axes[2].plot(filtered_signal, 'g-', alpha=0.7)\n",
    "axes[2].set_title(\"After Noise Removal (Final Filtered Signal)\")\n",
    "axes[2].set_xlabel(\"Sample Index\")\n",
    "axes[2].set_ylabel(\"Voltage\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = os.path.join(output_dir, f\"filtering_step.png\") \n",
    "# Save the figure\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Filtered signal properties:\")\n",
    "print(f\"  - Mean: {np.mean(filtered_signal):.4f}\")\n",
    "print(f\"  - Std Dev: {np.std(filtered_signal):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Zoom to region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 4: Zooming to Region of Interest ===\n",
      "Selecting portion from 0.1s to 2.1s\n",
      "Zoomed data figure saved to: results/20231103-M05-sucr-100-Gal-A1-02/zoomed_data.png\n",
      "Zoomed signal length: 60000 samples\n",
      "Time range: 0.10s to 2.10s\n"
     ]
    }
   ],
   "source": [
    "# === STEP 4: Zoom to Region of Interest ===\n",
    "print(\"\\n=== STEP 4: Zooming to Region of Interest ===\")\n",
    "print(f\"Selecting portion from {params['offset_time']}s to {params['offset_time'] + params['analysis_length']}s\")\n",
    "\n",
    "# Zoom and automatically save the figure\n",
    "zoomed_signal, current_time = preprocessing.zoom_to_region(\n",
    "    filtered_signal, \n",
    "    params,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "# Visualize zooming effect\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Full filtered signal with highlighted region\n",
    "time_full = np.arange(len(filtered_signal)) / params['sampling_rate']\n",
    "axes[0].plot(time_full, filtered_signal, 'b-', alpha=0.5)\n",
    "\n",
    "# Calculate indices for the zoomed region\n",
    "start_idx = int(params['offset_time'] * params['sampling_rate'])\n",
    "end_idx = int((params['offset_time'] + params['analysis_length']) * params['sampling_rate'])\n",
    "\n",
    "# Highlight the zoomed region\n",
    "axes[0].axvspan(params['offset_time'], params['offset_time'] + params['analysis_length'], \n",
    "                color='yellow', alpha=0.3)\n",
    "axes[0].set_title(\"Full Filtered Signal with Highlighted Analysis Region\")\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "axes[0].set_ylabel(\"Voltage\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoomed region\n",
    "axes[1].plot(current_time, zoomed_signal, 'g-')\n",
    "axes[1].set_title(\"Zoomed Region for Analysis\")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Voltage\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Zoomed signal length: {len(zoomed_signal)} samples\")\n",
    "print(f\"Time range: {current_time[0]:.2f}s to {current_time[-1]:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Signal Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 5: Signal Normalization (MAD) ===\n",
      "Normalizing signal using Median Absolute Deviation\n",
      "MAD normalization statistics:\n",
      "  - Original median: -5.3655\n",
      "  - Original MAD: 23.4957\n",
      "  - Normalized median: -0.2284\n",
      "  - Normalized MAD: 1.0000\n",
      "Successfully saved processed data to: results/20231103-M05-sucr-100-Gal-A1-02/interactive_processed.csv\n",
      "\n",
      "Saved processed data to: results/20231103-M05-sucr-100-Gal-A1-02/interactive_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# === STEP 5: Signal Normalization ===\n",
    "print(\"\\n=== STEP 5: Signal Normalization (MAD) ===\")\n",
    "print(\"Normalizing signal using Median Absolute Deviation\")\n",
    "\n",
    "# Calculate median and MAD for display\n",
    "median = np.median(zoomed_signal)\n",
    "mad = np.median(np.abs(zoomed_signal - median))\n",
    "mad_factor = 1.4826 * mad\n",
    "\n",
    "mad_signal = preprocessing.normalize_signal(zoomed_signal)\n",
    "\n",
    "# Visualize normalization effect\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Before normalization\n",
    "axes[0].plot(current_time, zoomed_signal, 'b-')\n",
    "axes[0].axhline(y=median, color='r', linestyle='-', label=f\"Median = {median:.4f}\")\n",
    "axes[0].axhline(y=median + mad_factor, color='g', linestyle='--', \n",
    "                label=f\"Median + MAD = {median + mad_factor:.4f}\")\n",
    "axes[0].axhline(y=median - mad_factor, color='g', linestyle='--', \n",
    "                label=f\"Median - MAD = {median - mad_factor:.4f}\")\n",
    "axes[0].set_title(\"Before MAD Normalization\")\n",
    "axes[0].set_ylabel(\"Voltage\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# After normalization\n",
    "axes[1].plot(current_time, mad_signal, 'g-')\n",
    "axes[1].axhline(y=0, color='r', linestyle='-', label=\"Median = 0\")\n",
    "axes[1].axhline(y=1, color='g', linestyle='--', label=\"Median + MAD = 1\")\n",
    "axes[1].axhline(y=-1, color='g', linestyle='--', label=\"Median - MAD = -1\")\n",
    "axes[1].set_title(\"After MAD Normalization\")\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Normalized Voltage\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = os.path.join(output_dir, f\"normalized_step.png\") \n",
    "# Save the figure\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"MAD normalization statistics:\")\n",
    "print(f\"  - Original median: {median:.4f}\")\n",
    "print(f\"  - Original MAD: {mad_factor:.4f}\")\n",
    "print(f\"  - Normalized median: {np.median(mad_signal):.4f}\")\n",
    "print(f\"  - Normalized MAD: {np.median(np.abs(mad_signal - np.median(mad_signal))) * 1.4826:.4f}\")\n",
    "\n",
    "# Save the processed data\n",
    "processed_data_path = os.path.join(output_dir, 'interactive_processed.csv')\n",
    "preprocessing.save_results(mad_signal, current_time, processed_data_path)\n",
    "print(f\"\\nSaved processed data to: {processed_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Spike Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 6: Interactive Spike Detection ===\n",
      "Adjust the threshold slider to set the optimal spike detection threshold\n",
      "Initial threshold calculated: 2.4326678633141707\n",
      "Data range: min=-4.425654472774549, max=10.593441813494758\n",
      "Selected threshold: 2.4326678633141707\n",
      "Final threshold value: 2.4326678633141707\n",
      "Using thresholds: upper=2.4327, lower=1.9461\n",
      "Detected 212 spikes using threshold = 2.43\n",
      "Spike details saved to: results/20231103-M05-sucr-100-Gal-A1-02/detected_spikes.csv\n"
     ]
    }
   ],
   "source": [
    "# === STEP 6: Interactive Spike Detection ===\n",
    "print(\"\\n=== STEP 6: Interactive Spike Detection ===\")\n",
    "print(\"Adjust the threshold slider to set the optimal spike detection threshold\")\n",
    "\n",
    "# Perform interactive threshold adjustment\n",
    "manual_threshold = spikes.adjust_threshold(mad_signal)\n",
    "\n",
    "# Detect spikes with the manual threshold\n",
    "spikes_file, spike_times, spike_values = spikes.detect_spikes_manual_threshold(\n",
    "    processed_data_path,\n",
    "    output_dir,\n",
    "    threshold=manual_threshold\n",
    ")\n",
    "\n",
    "y_offset = 0.5  # Adjust this value to change the separation\n",
    "\n",
    "# Plot the final result with detected spikes\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(current_time, mad_signal, 'b-', alpha=0.7, label=\"Normalized Signal\")\n",
    "plt.scatter(spike_times, spike_values + y_offset, color='r', s=50, label=\"Detected Spikes\")\n",
    "plt.axhline(y=manual_threshold, color='g', linestyle='--', label=f\"Threshold = {manual_threshold:.2f}\")\n",
    "plt.title(\"Final Result: Normalized Signal with Detected Spikes\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Normalized Voltage\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = os.path.join(output_dir, f\"trace_with_spikes.png\") \n",
    "# Save the figure\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Detected {len(spike_times)} spikes using threshold = {manual_threshold:.2f}\")\n",
    "print(f\"Spike details saved to: {spikes_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extract waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 7: Waveform Extraction and Analysis ===\n",
      "Extracting waveforms around each detected spike\n",
      "Plotting waveforms with average and standard deviation:\n",
      "Waveform figure saved to: results/20231103-M05-sucr-100-Gal-A1-02/waveforms_plot.png\n",
      "\n",
      "Extracted 212 waveforms\n",
      "Waveform duration: 3.0 ms (90 samples)\n",
      "Saved waveforms to: results/20231103-M05-sucr-100-Gal-A1-02/waveforms.csv\n",
      "\n",
      "Waveform metrics:\n",
      "Peak amplitude: 5.947\n",
      "Trough amplitude: -2.416\n",
      "Peak-to-trough amplitude: 8.363\n",
      "Peak time: 0.02 ms\n",
      "Trough time: 1.50 ms\n",
      "Peak-to-trough duration: 1.48 ms\n"
     ]
    }
   ],
   "source": [
    "# === STEP 7: Waveform Extraction and Analysis ===\n",
    "print(\"\\n=== STEP 7: Waveform Extraction and Analysis ===\")\n",
    "print(\"Extracting waveforms around each detected spike\")\n",
    "\n",
    "# Define waveform extraction parameters\n",
    "pre_peak_ms = 1.5  # milliseconds before spike\n",
    "post_peak_ms = 1.5  # milliseconds after spike\n",
    "\n",
    "# Use the existing extract_waveforms function\n",
    "waveforms_file = spikes.extract_waveforms(\n",
    "    data_file=processed_data_path,\n",
    "    spikes_file=spikes_file,\n",
    "    output_dir=output_dir,\n",
    "    pre_peak_length=pre_peak_ms,\n",
    "    post_peak_length=post_peak_ms\n",
    ")\n",
    "\n",
    "# Load the saved waveforms\n",
    "waveforms_df = pd.read_csv(waveforms_file)\n",
    "waveforms = waveforms_df.values\n",
    "\n",
    "# Use the enhanced plot_waveforms function that now includes average and std\n",
    "print(\"Plotting waveforms with average and standard deviation:\")\n",
    "avg_waveform, std_waveform = spikes.plot_waveforms(\n",
    "    waveforms, \n",
    "    pre_peak_ms=pre_peak_ms, \n",
    "    post_peak_ms=post_peak_ms,\n",
    "    show_time_axis=True,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "# Create a raster plot to visualize spike timing\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, spike_time in enumerate(spike_times):\n",
    "    plt.plot([spike_time, spike_time], [i-0.4, i+0.4], 'k-')\n",
    "    \n",
    "plt.title(\"Spike Raster Plot\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Spike Number\")\n",
    "plt.xlim(current_time[0], current_time[-1])\n",
    "plt.tight_layout()\n",
    "filename = os.path.join(output_dir, f\"rasters.png\") \n",
    "# Save the figure\n",
    "plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate time axis for metric calculations\n",
    "time_ms = np.linspace(-pre_peak_ms, post_peak_ms, waveforms.shape[1])\n",
    "\n",
    "# Calculate waveform metrics\n",
    "peak_idx = np.argmax(avg_waveform)\n",
    "trough_idx = np.argmin(avg_waveform)\n",
    "peak_amplitude = avg_waveform[peak_idx]\n",
    "trough_amplitude = avg_waveform[trough_idx]\n",
    "peak_to_trough = peak_amplitude - trough_amplitude\n",
    "\n",
    "# Calculate timing metrics\n",
    "peak_time = time_ms[peak_idx]\n",
    "trough_time = time_ms[trough_idx]\n",
    "peak_to_trough_duration = abs(trough_time - peak_time)\n",
    "\n",
    "print(f\"\\nExtracted {waveforms.shape[0]} waveforms\")\n",
    "print(f\"Waveform duration: {pre_peak_ms + post_peak_ms:.1f} ms ({waveforms.shape[1]} samples)\")\n",
    "print(f\"Saved waveforms to: {waveforms_file}\")\n",
    "\n",
    "print(\"\\nWaveform metrics:\")\n",
    "print(f\"Peak amplitude: {peak_amplitude:.3f}\")\n",
    "print(f\"Trough amplitude: {trough_amplitude:.3f}\")\n",
    "print(f\"Peak-to-trough amplitude: {peak_to_trough:.3f}\")\n",
    "print(f\"Peak time: {peak_time:.2f} ms\")\n",
    "print(f\"Trough time: {trough_time:.2f} ms\")\n",
    "print(f\"Peak-to-trough duration: {peak_to_trough_duration:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
